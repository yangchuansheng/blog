{"./":{"url":"./","title":" 序言","keywords":"","body":"Welcome to Prometheus 中文文档 &#x1F44B; 随着容器技术的迅速发展，Kubernetes 已然成为大家追捧的容器集群管理系统。Prometheus 作为生态圈 Cloud Native Computing Foundation（简称：CNCF）中的重要一员,其活跃度仅次于 Kubernetes, 现已广泛用于 Kubernetes 集群的监控系统中。 本文是 Prometheus 官方文档的中文版，同时包括了本人平时在使用 Prometheus 时的参考指南和实践总结，形成一个系统化的参考指南以方便查阅。欢迎大家关注和添加完善内容。 官方文档地址：https://prometheus.io/docs/introduction/overview/ &#x1F3E0; Homepage &#x1F680; 在线阅读 Gitbook : https://www.yangcs.net/prometheus/ Gitbook 新版 : https://ryanyang.gitbook.io/prometheus/ 项目源码 项目源码存放于 Github 上，https://github.com/yangchuansheng/prometheus-handbook。 本书版本更新记录 如无特殊说明，本指南所有文档仅适用于 Prometheus v2.6 及以上版本。 特殊语法 如果想标注出需要读者特别注意的地方，可以使用以下语法： > **[info] 注意** > > 冒号用来表示用户自定义的记录规则，不能在 exporter 中或监控对象直接暴露的指标中使用冒号来定义指标名称。 显示如下： 微信公众号 扫码关注微信公众号，坐上云原生的早班车。 作者 &#x1F464; Ryan Yang Github: @yangchuansheng Wechat: yangchuansheng572887 &#x1F91D; 贡献者 欢迎参与贡献和完善内容，贡献方法参考 CONTRIBUTING。感谢所有的贡献者，贡献者列表见 contributors。 支持我 如果觉得这个项目对你有帮助，请给我一个 ⭐️ 吧！ &#x1F4DD; License Copyright © 2019 Ryan Yang. This project is MIT licensed. Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"1-introduction/overview.html":{"url":"1-introduction/overview.html","title":"第1节：Prometheus 简介","keywords":"","body":"Prometheus 简介 什么是 Prometheus？ Prometheus 是由前 Google 工程师从 2012 年开始在 Soundcloud 以开源软件的形式进行研发的系统监控和告警工具包，自此以后，许多公司和组织都采用了 Prometheus 作为监控告警工具。Prometheus 的开发者和用户社区非常活跃，它现在是一个独立的开源项目，可以独立于任何公司进行维护。为了证明这一点，Prometheus 于 2016 年 5 月加入 CNCF 基金会，成为继 Kubernetes 之后的第二个 CNCF 托管项目。 有关 Prometheus 的详细信息，请参考后续章节 Prometheus 的优势 Prometheus 的主要优势有： 由指标名称和和键/值对标签标识的时间序列数据组成的多维数据模型。 强大的查询语言 PromQL。 不依赖分布式存储；单个服务节点具有自治能力。 时间序列数据是服务端通过 HTTP 协议主动拉取获得的。 也可以通过中间网关来推送时间序列数据。 可以通过静态配置文件或服务发现来获取监控目标。 支持多种类型的图表和仪表盘。 Prometheus 的组件 Prometheus 生态系统由多个组件组成，其中有许多组件是可选的： Prometheus Server 作为服务端，用来存储时间序列数据。 客户端库用来检测应用程序代码。 用于支持临时任务的推送网关。 Exporter 用来监控 HAProxy，StatsD，Graphite 等特殊的监控目标，并向 Prometheus 提供标准格式的监控样本数据。 alartmanager 用来处理告警。 其他各种周边工具。 其中大多数组件都是用 Go 编写的，因此很容易构建和部署为静态二进制文件。 Prometheus 的架构 Prometheus 的整体架构以及生态系统组件如下图所示： Prometheus Server 直接从监控目标中或者间接通过推送网关来拉取监控指标，它在本地存储所有抓取到的样本数据，并对此数据执行一系列规则，以汇总和记录现有数据的新时间序列或生成告警。可以通过 Grafana 或者其他工具来实现监控数据的可视化。 Prometheus 适用于什么场景 Prometheus 适用于记录文本格式的时间序列，它既适用于以机器为中心的监控，也适用于高度动态的面向服务架构的监控。在微服务的世界中，它对多维数据收集和查询的支持有特殊优势。Prometheus 是专为提高系统可靠性而设计的，它可以在断电期间快速诊断问题，每个 Prometheus Server 都是相互独立的，不依赖于网络存储或其他远程服务。当基础架构出现故障时，你可以通过 Prometheus 快速定位故障点，而且不会消耗大量的基础架构资源。 Prometheus 不适合什么场景 Prometheus 非常重视可靠性，即使在出现故障的情况下，你也可以随时查看有关系统的可用统计信息。如果你需要百分之百的准确度，例如按请求数量计费，那么 Prometheus 不太适合你，因为它收集的数据可能不够详细完整。这种情况下，你最好使用其他系统来收集和分析数据以进行计费，并使用 Prometheus 来监控系统的其余部分。 Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"2-concepts/data_model.html":{"url":"2-concepts/data_model.html","title":"第1节：数据模型","keywords":"","body":"数据模型 Prometheus 所有采集的监控数据均以指标（metric）的形式保存在内置的时间序列数据库当中（TSDB）：属于同一指标名称，同一标签集合的、有时间戳标记的数据流。除了存储的时间序列，Prometheus 还可以根据查询请求产生临时的、衍生的时间序列作为返回结果。 指标名称和标签 每一条时间序列由指标名称（Metrics Name）以及一组标签（键值对）唯一标识。其中指标的名称（metric name）可以反映被监控样本的含义（例如，http_requests_total — 表示当前系统接收到的 HTTP 请求总量），指标名称只能由 ASCII 字符、数字、下划线以及冒号组成，同时必须匹配正则表达式 [a-zA-Z_:][a-zA-Z0-9_:]*。 [info] 注意 冒号用来表示用户自定义的记录规则，不能在 exporter 中或监控对象直接暴露的指标中使用冒号来定义指标名称。 通过使用标签，Prometheus 开启了强大的多维数据模型：对于相同的指标名称，通过不同标签列表的集合，会形成特定的度量维度实例（例如：所有包含度量名称为 /api/tracks 的 http 请求，打上 method=POST 的标签，就会形成具体的 http 请求）。该查询语言在这些指标和标签列表的基础上进行过滤和聚合。改变任何度量指标上的任何标签值（包括添加或删除指标），都会创建新的时间序列。 标签的名称只能由 ASCII 字符、数字以及下划线组成并满足正则表达式 [a-zA-Z_][a-zA-Z0-9_]*。其中以 __ 作为前缀的标签，是系统保留的关键字，只能在系统内部使用。标签的值则可以包含任何 Unicode 编码的字符。 更多详细内容请参考 指标和标签命名最佳实践。 样本 在时间序列中的每一个点称为一个样本（sample），样本由以下三部分组成： 指标（metric）：指标名称和描述当前样本特征的 labelsets； 时间戳（timestamp）：一个精确到毫秒的时间戳； 样本值（value）： 一个 folat64 的浮点型数据表示当前样本的值。 表示方式 通过如下表达方式表示指定指标名称和指定标签集合的时间序列： {=, ...} 例如，指标名称为 api_http_requests_total，标签为 method=\"POST\" 和 handler=\"/messages\" 的时间序列可以表示为： api_http_requests_total{method=\"POST\", handler=\"/messages\"} 这与 OpenTSDB 中使用的标记法相同。 Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"2-concepts/metric_types.html":{"url":"2-concepts/metric_types.html","title":"第2节：指标类型","keywords":"","body":"Prometheus 的客户端库中提供了四种核心的指标类型。但这些类型只是在客户端库（客户端可以根据不同的数据类型调用不同的 API 接口）和在线协议中，实际在 Prometheus server 中并不对指标类型进行区分，而是简单地把这些指标统一视为无类型的时间序列。不过，将来我们会努力改变这一现状的。 Counter（计数器） Counter 类型代表一种样本数据单调递增的指标，即只增不减，除非监控系统发生了重置。例如，你可以使用 counter 类型的指标来表示服务的请求数、已完成的任务数、错误发生的次数等。counter 主要有两个方法： //将counter值加1. Inc() // 将指定值加到counter值上，如果指定值 Counter 类型数据可以让用户方便的了解事件产生的速率的变化，在 PromQL 内置的相关操作函数可以提供相应的分析，比如以 HTTP 应用请求量来进行说明： //通过rate()函数获取HTTP请求量的增长率 rate(http_requests_total[5m]) //查询当前系统中，访问量前10的HTTP地址 topk(10, http_requests_total) 不要将 counter 类型应用于样本数据非单调递增的指标，例如：当前运行的进程数量（应该用 Guage 类型）。 不同语言关于 Counter 的客户端库使用文档： Go Java Python Ruby Guage（仪表盘） Guage 类型代表一种样本数据可以任意变化的指标，即可增可减。guage 通常用于像温度或者内存使用率这种指标数据，也可以表示能随时增加或减少的“总数”，例如：当前并发请求的数量。 对于 Gauge 类型的监控指标，通过 PromQL 内置函数 delta() 可以获取样本在一段时间内的变化情况，例如，计算 CPU 温度在两小时内的差异： dalta(cpu_temp_celsius{host=\"zeus\"}[2h]) 你还可以通过PromQL 内置函数 predict_linear() 基于简单线性回归的方式，对样本数据的变化趋势做出预测。例如，基于 2 小时的样本数据，来预测主机可用磁盘空间在 4 个小时之后的剩余情况： predict_linear(node_filesystem_free{job=\"node\"}[2h], 4 * 3600) 不同语言关于 Guage 的客户端库使用文档： Go Java Python Ruby Histogram（直方图） 在大多数情况下人们都倾向于使用某些量化指标的平均值，例如 CPU 的平均使用率、页面的平均响应时间。这种方式的问题很明显，以系统 API 调用的平均响应时间为例：如果大多数 API 请求都维持在 100ms 的响应时间范围内，而个别请求的响应时间需要 5s，那么就会导致某些 WEB 页面的响应时间落到中位数的情况，而这种现象被称为长尾问题。 为了区分是平均的慢还是长尾的慢，最简单的方式就是按照请求延迟的范围进行分组。例如，统计延迟在 0~10ms 之间的请求数有多少而 10~20ms 之间的请求数又有多少。通过这种方式可以快速分析系统慢的原因。Histogram 和 Summary 都是为了能够解决这样问题的存在，通过 Histogram 和 Summary 类型的监控指标，我们可以快速了解监控样本的分布情况。 Histogram 在一段时间范围内对数据进行采样（通常是请求持续时间或响应大小等），并将其计入可配置的存储桶（bucket）中，后续可通过指定区间筛选样本，也可以统计样本总数，最后一般将数据展示为直方图。 Histogram 类型的样本会提供三种指标（假设指标名称为 ）： 样本的值分布在 bucket 中的数量，命名为 _bucket{le=\"\"}。解释的更通俗易懂一点，这个值表示指标值小于等于上边界的所有样本数量。 // 在总共2次请求当中。http 请求响应时间 所有样本值的大小总和，命名为 _sum。 // 实际含义： 发生的2次 http 请求总的响应时间为 13.107670803000001 秒 io_namespace_http_requests_latency_seconds_histogram_sum{path=\"/\",method=\"GET\",code=\"200\",} 13.107670803000001 样本总数，命名为 _count。值和 _bucket{le=\"+Inf\"} 相同。 // 实际含义： 当前一共发生了 2 次 http 请求 io_namespace_http_requests_latency_seconds_histogram_count{path=\"/\",method=\"GET\",code=\"200\",} 2.0 [info] 注意 bucket 可以理解为是对数据指标值域的一个划分，划分的依据应该基于数据值的分布。注意后面的采样点是包含前面的采样点的，假设 xxx_bucket{...,le=\"0.01\"} 的值为 10，而 xxx_bucket{...,le=\"0.05\"} 的值为 30，那么意味着这 30 个采样点中，有 10 个是小于 10 ms 的，其余 20 个采样点的响应时间是介于 10 ms 和 50 ms 之间的。 可以通过 histogram_quantile() 函数来计算 Histogram 类型样本的分位数。分位数可能不太好理解，你可以理解为分割数据的点。我举个例子，假设样本的 9 分位数（quantile=0.9）的值为 x，即表示小于 x 的采样值的数量占总体采样值的 90%。Histogram 还可以用来计算应用性能指标值（Apdex score）。 不同语言关于 Histogram 的客户端库使用文档： Go Java Python Ruby Summary（摘要） 与 Histogram 类型类似，用于表示一段时间内的数据采样结果（通常是请求持续时间或响应大小等），但它直接存储了分位数（通过客户端计算，然后展示出来），而不是通过区间来计算。 Summary 类型的样本也会提供三种指标（假设指标名称为 ）： 样本值的分位数分布情况，命名为 {quantile=\"\"}。 // 含义：这 12 次 http 请求中有 50% 的请求响应时间是 3.052404983s io_namespace_http_requests_latency_seconds_summary{path=\"/\",method=\"GET\",code=\"200\",quantile=\"0.5\",} 3.052404983 // 含义：这 12 次 http 请求中有 90% 的请求响应时间是 8.003261666s io_namespace_http_requests_latency_seconds_summary{path=\"/\",method=\"GET\",code=\"200\",quantile=\"0.9\",} 8.003261666 所有样本值的大小总和，命名为 _sum。 // 含义：这12次 http 请求的总响应时间为 51.029495508s io_namespace_http_requests_latency_seconds_summary_sum{path=\"/\",method=\"GET\",code=\"200\",} 51.029495508 样本总数，命名为 _count。 // 含义：当前一共发生了 12 次 http 请求 io_namespace_http_requests_latency_seconds_summary_count{path=\"/\",method=\"GET\",code=\"200\",} 12.0 现在可以总结一下 Histogram 与 Summary 的异同： 它们都包含了 _sum 和 _count 指标 Histogram 需要通过 _bucket 来计算分位数，而 Summary 则直接存储了分位数的值。 关于 Summary 与 Histogram 的详细用法，请参考 histograms and summaries。 不同语言关于 Summary 的客户端库使用文档： Go Java Python Ruby 参考 如何区分prometheus中Histogram和Summary类型的metrics？ Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/gettingstarted.html":{"url":"3-prometheus/gettingstarted.html","title":"快速开始","keywords":"","body":"快速开始 译者：詹叶 本文类似 “Hello World” 的向导，教你怎么安装，配置，并且用一个简单的例子演示如何使用 Prometheus。你可以在本地下载并运行 Prometheus，配置以采集自身和示例应用的运行数据，然后使用查询语句，规则和图形来使用收集到的时间序列数据。 下载和运行 Prometheus 为你的平台下载最新版本的 Prometheus，执行以下命令解压： tar xvfz prometheus-*.tar.gz cd prometheus-* 在启动 Prometheus 之前，我们先做一些配置。 配置 Prometheus 来监控自己 Prometheus 通过在目标节点的 HTTP 端口上采集 metrics（遥测专用词，度量指标）来监控目标节点（以下会称为“采样目标”）。因为 Prometheus 也以相同的方式暴露自己的数据，所以他也可以采集和检查自己的健康状况。 虽然在生产实践中 Prometheus 服务器只收集自己的数据没多大作用，但是这是个不错的入门示例。保存以下基础配置到文件 prometheus.yml 中： global: scrape_interval: 15s # By default, scrape targets every 15 seconds. # Attach these labels to any time series or alerts when communicating with # external systems (federation, remote storage, Alertmanager). external_labels: monitor: 'codelab-monitor' # A scrape configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrape_configs: # The job name is added as a label `job=` to any timeseries scraped from this config. - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] 完整配置选项说明，请查看配置文档 启动 Prometheus 使用上一步创建的配置文件启动 Prometheus，修改以下命令为你的平台中 Prometheus 二进制文件所在路径，执行命令启动： # Start Prometheus. # By default, Prometheus stores its database in ./data (flag --storage.tsdb.path). ./prometheus --config.file=prometheus.yml 此时 Prometheus 应该启动了。你应该也可以通过浏览器打开状态页面 localhost:9090。稍等几秒钟 Prometheus 就可以从自己的 HTTP metrics 端点收集自己的数据。 你也可以访问 metrics 端点 localhost:9090/metrics 验证 Prometheus 是否正在提供 metrics 服务。 使用表达式浏览器 让我们来看看 Prometheus 已经收集到的自己的 metrics 数据。为了使用 Prometheus 内置的表达式浏览器，访问 http://localhost:9090/graph 选择\"Graph\" 标签页中的 “Console” 视图 正如你可以从 localhost:9090/metrics 收集 metrics，Prometheus 暴露的一个度量指标称为 prometheus_target_interval_length_seconds（目标擦除之间的实际时间量）。继续在表达式控制台输入： prometheus_target_interval_length_seconds 此时应该返回许多不同的时间序列(以及每条记录的最新值)，所有时间序列都有 metric 名称 prometheus_target_interval_length_seconds ，但具有不同的标签。这些标签指定不同延迟百分比和目标组间隔。 如果我们只关心99%延迟，可以使用以下查询语句来检索信息： prometheus_target_interval_length_seconds{quantile=\"0.99\"} 要计算返回的时间序列数量，可以输入： count(prometheus_target_interval_length_seconds) 更多表达式语言，请看 expression language documentation 使用绘图接口 访问 http://localhost:9090/graph 并选择\"Graph\" 标签页，打开图形绘制界面 例如，输入以下表达式来绘制 Prometheus 自我采集每秒创建块的速率： rate(prometheus_tsdb_head_chunks_created_total[1m]) 实验采用图形范围参数和其他设置。 启动一些示例应用 让我们玩点更有意思的东西，启动一些样例目标让 Prometheus 采集。 Go 客户端库包含一个示例，该示例为具有不同延迟分布的三个服务暴露 RPC 延迟。 确保你已经安装了 Go 语言编译器并且指定 Go 工作目录 (在环境变量中指定正确的 GOPATH) 下载 Prometheus 的 Go 客户端库并运行这三个示例： # Fetch the client library code and compile example. git clone https://github.com/prometheus/client_golang.git cd client_golang/examples/random go get -d go build # Start 3 example targets in separate terminals: ./random -listen-address=:8080 ./random -listen-address=:8081 ./random -listen-address=:8082 此时监听目标启动 http://localhost:8080/metrics, http://localhost:8081/metrics 和 http://localhost:8082/metrics 配置 Prometheus 来监控示例目标 现在我们配置 Prometheus 来采集这些新的目标。让我们将这三个目标分组到一个名为 example-random的作业。但是，假设前两个端点（即： http://localhost:8080/metrics, http://localhost:8081/metrics ）都是生产级目标应用，第三个端点（即： http://localhost:8082/metrics ）为金丝雀实例。要在 Prometheus 中对此进行建模，我们可以将多组端点添加到单个作业中，为每组目标添加额外的标签。 在此示例中，我们将 group =“production” 标签添加到第一组目标，同时将 group =“canary” 添加到第二组。 要实现此目的，请将以下作业定义添加到 prometheus.yml 中的 scrape_configs 部分，然后重新启动 Prometheus 实例： scrape_configs: - job_name: 'example-random' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:8080', 'localhost:8081'] labels: group: 'production' - targets: ['localhost:8082'] labels: group: 'canary' 转到表达式浏览器并验证 Prometheus 现在是否有关于这些示例端点公开的时间序列的信息，例如 rpc_durations_seconds 的 metric 指标。 配置规则聚合抓取的数据到新的时间序列 在计算ad-hoc时，聚合了上千个时间序列会使查询会变慢，虽然在我们的示例中不会有这样的问题。 为了提高效率，Prometheus允许您通过配置的录制规则将表达式预先记录到全新的持久时间序列中。假设我们关心的是记录在5分钟窗口内测量的所有实例（但保留作业和服务维度）的 RPC 的平均每秒速率（rpc_durations_seconds_count）。 我们可以这样写： avg(rate(rpc_durations_seconds_count[5m])) by (job, service) 尝试绘制此表达式。 要将此表达式生成的时间序列记录到名为 job_service：rpc_durations_seconds_count：avg_rate5m 的新的 metric 指标中，请使用以下记录规则创建一个文件并将其另存为prometheus.rules.yml： groups: - name: example rules: - record: job_service:rpc_durations_seconds_count:avg_rate5m expr: avg(rate(rpc_durations_seconds_count[5m])) by (job, service) 要使 Prometheus 使用此新规则，需要在 prometheus.yml 中添加 rule_files 语句。 配置现在应该如下所示： global: scrape_interval: 15s # By default, scrape targets every 15 seconds. evaluation_interval: 15s # Evaluate rules every 15 seconds. # Attach these extra labels to all timeseries collected by this Prometheus instance. external_labels: monitor: 'codelab-monitor' rule_files: - 'prometheus.rules.yml' scrape_configs: - job_name: 'prometheus' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:9090'] - job_name: 'example-random' # Override the global default and scrape targets from this job every 5 seconds. scrape_interval: 5s static_configs: - targets: ['localhost:8080', 'localhost:8081'] labels: group: 'production' - targets: ['localhost:8082'] labels: group: 'canary' 重启 Prometheus 是新配置生效，并通过表达式浏览器查询或绘制图表来验证带有新 metric 指标名称 job_service：rpc_durations_seconds_count：avg_rate5m 的新时间序列现在可用。 Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/installation.html":{"url":"3-prometheus/installation.html","title":"安装","keywords":"","body":"安装 译者：詹叶 使用预编译二进制文件 我们为绝大部分 Prometheus 组件提供预编译二进制文件。查看下载获取所有可用版本列表。 从源代码构建 要从源代码构建 Prometheus 组件，请查看相应仓库中的 Makefile。 使用Docker 所有可用的 Prometheus 容器镜像可在公有镜像仓库 Quay.io 或者 Docker Hub 中获取。 使用 Docker 运行 Prometheus 相当简单，只需要命名 docker run -p 9090:9090 prom/prometheus，Prometheus 将使用一个简单的配置文件启动并暴露服务到9090端口。 Prometheus 容器镜像使用卷来存储实际的 metrics 指标。对于生产部署，强烈推荐使用 容器数据卷 来简化 Prometheus 升级时的数据管理操作。 绑定及挂载数据卷 用以下命令将主机文件系统中的 prometheus.yml 挂载到容器中： docker run -p 9090:9090 -v /tmp/prometheus.yml:/etc/prometheus/prometheus.yml \\ prom/prometheus 或者使用额外的数据卷挂载配置文件： docker run -p 9090:9090 -v /prometheus-data \\ prom/prometheus --config.file=/prometheus-data/prometheus.yml 自定义容器镜像 为了避免挂载主机文件到容器中的操作，可以将配置文件封装入容器镜像中。此方法适用于配置文件基本稳定（变更小）并且在所有环境中都相同的情况。 创建一个新的路径来存放 Prometheus 配置文件， Dockerfile 如下： FROM prom/prometheus ADD prometheus.yml /etc/prometheus/ 执行以下命令构建新镜像，并运行容器： docker build -t my-prometheus . docker run -p 9090:9090 my-prometheus 更高级的选项是在容器启动时，使用某些动态配置管理工具或者守护程序定期更新配置。 使用配置管理系统 如果你更喜欢使用配置管理系统，你可能会对以下几种第三方工具感兴趣： Ansible Cloud Alchemy/ansible-prometheus Chef rayrod2030/chef-prometheus Puppet puppet/prometheus SaltStack bechtoldt/saltstack-prometheus-formula Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/basics.html":{"url":"3-prometheus/basics.html","title":"初识 PromQL","keywords":"","body":"初识 PromQL Prometheus 提供了一种功能表达式语言 PromQL，允许用户实时选择和汇聚时间序列数据。表达式的结果可以在浏览器中显示为图形，也可以显示为表格数据，或者由外部系统通过 HTTP API 调用。 例子 本节仅供参考，想进一步学习可以通过后面的例子入手。 表达式语言数据类型 在 Prometheus 的表达式语言中，表达式或子表达式包括以下四种类型之一： 瞬时向量（Instant vector） - 一组时间序列，每个时间序列包含单个样本，它们共享相同的时间戳。也就是说，表达式的返回值中只会包含该时间序列中的最新的一个样本值。而相应的这样的表达式称之为瞬时向量表达式。 区间向量（Range vector） - 一组时间序列，每个时间序列包含一段时间范围内的样本数据。 标量（Scalar） - 一个浮点型的数据值。 字符串（String） - 一个简单的字符串值。 根用户输入的表达式返回的数据类型是否合法取决于用例的不同，例如：瞬时向量表达式返回的数据类型是唯一可以直接绘制成图表的数据类型。 字面量 字符串 字符串可以用单引号、双引号或反引号指定为文字常量。 PromQL 遵循与 Go 相同的转义规则。在单引号或双引号中，用反斜杠来表示转义序列，后面可以跟 a, b, f, n, r, t, v 或 \\。特殊字符可以使用八进制（\\nnn）或者十六进制（\\xnn，\\unnnn 和 \\Unnnnnnnn）。 与 Go 不同，Prometheus 不会对反引号内的换行符进行转义。 例如： \"this is a string\" 'these are unescaped: \\n \\\\ \\t' `these are not unescaped: \\n ' \" \\t` 标量 标量浮点值可以字面上写成 [-](digits)[.(digits)] 的形式。 -2.43 时间序列过滤器 瞬时向量过滤器 瞬时向量过滤器允许在指定的时间戳内选择一组时间序列和每个时间序列的单个样本值。在最简单的形式中，近指定指标（metric）名称。这将生成包含此指标名称的所有时间序列的元素的瞬时向量。 例如：选择指标名称为 http_requests_total 的所有时间序列： http_requests_total 可以通过向花括号（{}）里附加一组标签来进一步过滤时间序列。 例如：选择指标名称为 http_requests_total，job 标签值为 prometheus，group 标签值为 canary 的时间序列： http_requests_total{job=\"prometheus\",group=\"canary\"} PromQL 还支持用户根据时间序列的标签匹配模式来对时间序列进行过滤，目前主要支持两种匹配模式：完全匹配和正则匹配。总共有以下几种标签匹配运算符： = : 选择与提供的字符串完全相同的标签。 != : 选择与提供的字符串不相同的标签。 =~ : 选择正则表达式与提供的字符串（或子字符串）相匹配的标签。 !~ : 选择正则表达式与提供的字符串（或子字符串）不匹配的标签。 例如：选择指标名称为 http_requests_total，环境为 staging、testing 或 development，HTTP 方法为 GET 的时间序列： http_requests_total{environment=~\"staging|testing|development\",method!=\"GET\"} 没有指定标签的标签过滤器会选择该指标名称的所有时间序列。 所有的 PromQL 表达式必须至少包含一个指标名称，或者一个不会匹配到空字符串的标签过滤器。 以下表达式是非法的（因为会匹配到空字符串）： {job=~\".*\"} # 非法！ 以下表达式是合法的： {job=~\".+\"} # 合法！ {job=~\".*\",method=\"get\"} # 合法！ 除了使用 {label=value} 的形式以外，我们还可以使用内置的 __name__ 标签来指定监控指标名称。例如：表达式 http_requests_total 等效于 {__name__=\"http_requests_total\"}。也可以使用除 = 之外的过滤器（=，=~，~）。以下表达式选择指标名称以 job: 开头的所有指标： {__name__=~\"job:.*\"} Prometheus 中的所有正则表达式都使用 RE2语法。 区间向量过滤器 区间向量与瞬时向量的工作方式类似，唯一的差异在于在区间向量表达式中我们需要定义时间选择的范围，时间范围通过时间范围选择器 [] 进行定义，以指定应为每个返回的区间向量样本值中提取多长的时间范围。 时间范围通过数字来表示，单位可以使用以下其中之一的时间单位： s - 秒 m - 分钟 h - 小时 d - 天 w - 周 y - 年 例如：选择在过去 5 分钟内指标名称为 http_requests_total，job 标签值为 prometheus 的所有时间序列： http_requests_total{job=\"prometheus\"}[5m] 时间位移操作 在瞬时向量表达式或者区间向量表达式中，都是以当前时间为基准： http_request_total{} # 瞬时向量表达式，选择当前最新的数据 http_request_total{}[5m] # 区间向量表达式，选择以当前时间为基准，5分钟内的数据 而如果我们想查询，5 分钟前的瞬时样本数据，或昨天一天的区间内的样本数据呢? 这个时候我们就可以使用位移操作，位移操作的关键字为 offset。 例如，以下表达式返回相对于当前查询时间过去 5 分钟的 http_requests_total 值： http_requests_total offset 5m 注意：offset 关键字需要紧跟在选择器（{}）后面。以下表达式是正确的： sum(http_requests_total{method=\"GET\"} offset 5m) // GOOD. 下面的表达式是不合法的： sum(http_requests_total{method=\"GET\"}) offset 5m // INVALID. 该操作同样适用于区间向量。以下表达式返回指标 http_requests_total 一周前的 5 分钟之内的 HTTP 请求量的增长率： rate(http_requests_total[5m] offset 1w) 操作符 使用PromQL除了能够方便的按照查询和过滤时间序列以外，PromQL还支持丰富的操作符，用户可以使用这些操作符对进一步的对事件序列进行二次加工。这些操作符包括：数学运算符，逻辑运算符，布尔运算符等等。详细描述请参考 PromQL 操作符。 内置函数 Prometheus 提供了大量的内置函数来处理时序数据，详细描述请参考 PromQL 内置函数。 陷阱 失效 执行查询操作时，独立于当前时刻被选中的时间序列数据所对应的时间戳，这个时间戳主要用来进行聚合操作，包括 sum, avg 等，大多数聚合的时间序列数据所对应的时间戳没有对齐。由于它们的独立性，我们需要在这些时间戳中选择一个时间戳，并已这个时间戳为基准，获取小于且最接近这个时间戳的时间序列数据。 如果采样目标或告警规则不再返回之前存在的时间序列的样本，则该时间序列将被标记为失效。如果删除了采样目标，则之前返回的时间序列也会很快被标记为失效。 如果在某个时间序列被标记为失效后在该时间戳处执行查询操作，则不会为该时间序列返回任何值。如果随后在该时间序列中插入了新的样本，则照常返回时间序列数据。 如果在采样时间戳前 5 分钟（默认情况）未找到任何样本，则该时间戳不会返回任何任何该时间序列的值。这实际上意味着你在图表中看到的数据都是在当前时刻 5 分钟前的数据。 对于在采样点中包含时间戳的时间序列，不会被标记为失效。在这种情况下，仅使用 5 分钟阈值检测的规则。 避免慢查询和高负载 如果一个查询需要操作非常大的数据量，图表绘制很可能会超时，或者服务器负载过高。因此，在对未知数据构建查询时，始终需要在 Prometheus 表达式浏览器的表格视图中构建查询，直到结果是看起来合理的（最多为数百个，而不是数千个）。只有当你已经充分过滤或者聚合数据时，才切换到图表模式。如果表达式的查询结果仍然需要很长时间才能绘制出来，则需要通过记录规则重新清洗数据。 像 api_http_requests_total 这样简单的度量指标名称选择器，可以扩展到具有不同标签的数千个时间序列中，这对于 Prometheus 的查询语言是非常重要的。还要记住，对于聚合操作来说，即使输出的时间序列集非常少，它也会在服务器上产生负载。这类似于在关系型数据库中查询一个字段的总和，总是非常缓慢。 Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/operators.html":{"url":"3-prometheus/operators.html","title":"操作符","keywords":"","body":"操作符 二元运算符 Prometheus 的查询语言支持基本的逻辑运算和算术运算。对于两个瞬时向量, 匹配行为可以被改变。 算术二元运算符 在 Prometheus 系统中支持下面的二元算术运算符： + 加法 - 减法 * 乘法 / 除法 % 模 ^ 幂等 二元运算操作符支持 scalar/scalar(标量/标量)、vector/scalar(向量/标量)、和 vector/vector(向量/向量) 之间的操作。 在两个标量之间进行数学运算，得到的结果也是标量。 在向量和标量之间，这个运算符会作用于这个向量的每个样本值上。例如：如果一个时间序列瞬时向量除以 2，操作结果也是一个新的瞬时向量，且度量指标名称不变, 它是原度量指标瞬时向量的每个样本值除以 2。 如果是瞬时向量与瞬时向量之间进行数学运算时，过程会相对复杂一点，运算符会依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行运算，如果没找到匹配元素，则直接丢弃。同时新的时间序列将不会包含指标名称。 例如，如果我们想根据 node_disk_bytes_written 和 node_disk_bytes_read 获取主机磁盘IO的总量，可以使用如下表达式： node_disk_bytes_written + node_disk_bytes_read 该表达式返回结果的示例如下所示： {device=\"sda\",instance=\"localhost:9100\",job=\"node_exporter\"}=>1634967552@1518146427.807 + 864551424@1518146427.807 {device=\"sdb\",instance=\"localhost:9100\",job=\"node_exporter\"}=>0@1518146427.807 + 1744384@1518146427.807 布尔运算符 目前，Prometheus 支持以下布尔运算符： == (相等) != (不相等) > (大于) (小于) >= (大于等于) (小于等于) 布尔运算符被应用于 scalar/scalar（标量/标量）、vector/scalar（向量/标量），和vector/vector（向量/向量）。默认情况下布尔运算符只会根据时间序列中样本的值，对时间序列进行过滤。我们可以通过在运算符后面使用 bool 修饰符来改变布尔运算的默认行为。使用 bool 修改符后，布尔运算不会对时间序列进行过滤，而是直接依次瞬时向量中的各个样本数据与标量的比较结果 0 或者 1。 在两个标量之间进行布尔运算，必须提供 bool 修饰符，得到的结果也是标量，即 0（false）或 1（true）。例如： 2 > bool 1 # 结果为 1 瞬时向量和标量之间的布尔运算，这个运算符会应用到某个当前时刻的每个时序数据上，如果一个时序数据的样本值与这个标量比较的结果是 false，则这个时序数据被丢弃掉，如果是 true, 则这个时序数据被保留在结果中。如果提供了 bool 修饰符，那么比较结果是 0 的时序数据被丢弃掉，而比较结果是 1 的时序数据被保留。例如： http_requests_total > 100 # 结果为 true 或 false http_requests_total > bool 100 # 结果为 1 或 0 瞬时向量与瞬时向量直接进行布尔运算时，同样遵循默认的匹配模式：依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行相应的操作，如果没找到匹配元素，或者计算结果为 false，则直接丢弃。如果匹配上了，则将左边向量的度量指标和标签的样本数据写入瞬时向量。如果提供了 bool 修饰符，那么比较结果是 0 的时序数据被丢弃掉，而比较结果是 1 的时序数据（只保留左边向量）被保留。 集合运算符 使用瞬时向量表达式能够获取到一个包含多个时间序列的集合，我们称为瞬时向量。 通过集合运算，可以在两个瞬时向量与瞬时向量之间进行相应的集合操作。目前，Prometheus 支持以下集合运算符： and (并且) or (或者) unless (排除) vector1 and vector2 会产生一个由 vector1 的元素组成的新的向量。该向量包含 vector1 中完全匹配 vector2 中的元素组成。 vector1 or vector2 会产生一个新的向量，该向量包含 vector1 中所有的样本数据，以及 vector2 中没有与 vector1 匹配到的样本数据。 vector1 unless vector2 会产生一个新的向量，新向量中的元素由 vector1 中没有与 vector2 匹配的元素组成。 匹配模式 向量与向量之间进行运算操作时会基于默认的匹配规则：依次找到与左边向量元素匹配（标签完全一致）的右边向量元素进行运算，如果没找到匹配元素，则直接丢弃。 接下来将介绍在 PromQL 中有两种典型的匹配模式：一对一（one-to-one）,多对一（many-to-one）或一对多（one-to-many）。 一对一匹配 一对一匹配模式会从操作符两边表达式获取的瞬时向量依次比较并找到唯一匹配(标签完全一致)的样本值。默认情况下，使用表达式： vector1 vector2 在操作符两边表达式标签不一致的情况下，可以使用 on(label list) 或者 ignoring(label list）来修改便签的匹配行为。使用 ignoreing 可以在匹配时忽略某些便签。而 on 则用于将匹配行为限定在某些便签之内。 ignoring() on() 例如当存在样本： method_code:http_errors:rate5m{method=\"get\", code=\"500\"} 24 method_code:http_errors:rate5m{method=\"get\", code=\"404\"} 30 method_code:http_errors:rate5m{method=\"put\", code=\"501\"} 3 method_code:http_errors:rate5m{method=\"post\", code=\"500\"} 6 method_code:http_errors:rate5m{method=\"post\", code=\"404\"} 21 method:http_requests:rate5m{method=\"get\"} 600 method:http_requests:rate5m{method=\"del\"} 34 method:http_requests:rate5m{method=\"post\"} 120 使用 PromQL 表达式： method_code:http_errors:rate5m{code=\"500\"} / ignoring(code) method:http_requests:rate5m 该表达式会返回在过去 5 分钟内，HTTP 请求状态码为 500 的在所有请求中的比例。如果没有使用 ignoring(code)，操作符两边表达式返回的瞬时向量中将找不到任何一个标签完全相同的匹配项。 因此结果如下： {method=\"get\"} 0.04 // 24 / 600 {method=\"post\"} 0.05 // 6 / 120 同时由于 method 为 put 和 del 的样本找不到匹配项，因此不会出现在结果当中。 多对一和一对多 多对一和一对多两种匹配模式指的是“一”侧的每一个向量元素可以与\"多\"侧的多个元素匹配的情况。在这种情况下，必须使用 group 修饰符：group_left 或者 group_right 来确定哪一个向量具有更高的基数（充当“多”的角色）。 ignoring() group_left() ignoring() group_right() on() group_left() on() group_right() 多对一和一对多两种模式一定是出现在操作符两侧表达式返回的向量标签不一致的情况。因此需要使用 ignoring 和 on 修饰符来排除或者限定匹配的标签列表。 例如，使用表达式： method_code:http_errors:rate5m / ignoring(code) group_left method:http_requests:rate5m 该表达式中，左向量 method_code:http_errors:rate5m 包含两个标签 method 和 code。而右向量 method:http_requests:rate5m 中只包含一个标签 method，因此匹配时需要使用 ignoring 限定匹配的标签为 code。 在限定匹配标签后，右向量中的元素可能匹配到多个左向量中的元素 因此该表达式的匹配模式为多对一，需要使用 group 修饰符 group_left 指定左向量具有更好的基数。 最终的运算结果如下： {method=\"get\", code=\"500\"} 0.04 // 24 / 600 {method=\"get\", code=\"404\"} 0.05 // 30 / 600 {method=\"post\", code=\"500\"} 0.05 // 6 / 120 {method=\"post\", code=\"404\"} 0.175 // 21 / 120 提醒：group 修饰符只能在比较和数学运算符中使用。在逻辑运算 and，unless 和 or 操作中默认与右向量中的所有元素进行匹配。 聚合操作 Prometheus 还提供了下列内置的聚合操作符，这些操作符作用域瞬时向量。可以将瞬时表达式返回的样本数据进行聚合，形成一个具有较少样本值的新的时间序列。 sum (求和) min (最小值) max (最大值) avg (平均值) stddev (标准差) stdvar (标准差异) count (计数) count_values (对 value 进行计数) bottomk (样本值最小的 k 个元素) topk (样本值最大的k个元素) quantile (分布统计) 这些操作符被用于聚合所有标签维度，或者通过 without 或者 by 子语句来保留不同的维度。 ([parameter,] ) [without|by ()] 其中只有 count_values, quantile, topk, bottomk 支持参数(parameter)。 without 用于从计算结果中移除列举的标签，而保留其它标签。by 则正好相反，结果向量中只保留列出的标签，其余标签则移除。通过 without 和 by 可以按照样本的问题对数据进行聚合。 例如： 如果指标 http_requests_total 的时间序列的标签集为 application, instance, 和 group，我们可以通过以下方式计算所有 instance 中每个 application 和 group 的请求总量： sum(http_requests_total) without (instance) 等价于 sum(http_requests_total) by (application, group) 如果只需要计算整个应用的 HTTP 请求总量，可以直接使用表达式： sum(http_requests_total) count_values 用于时间序列中每一个样本值出现的次数。count_values 会为每一个唯一的样本值输出一个时间序列，并且每一个时间序列包含一个额外的标签。这个标签的名字由聚合参数指定，同时这个标签值是唯一的样本值。 例如要计算运行每个构建版本的二进制文件的数量： count_values(\"version\", build_version) 返回结果如下： {count=\"641\"} 1 {count=\"3226\"} 2 {count=\"644\"} 4 topk 和 bottomk 则用于对样本值进行排序，返回当前样本值前 n 位，或者后 n 位的时间序列。 获取 HTTP 请求数前 5 位的时序样本数据，可以使用表达式： topk(5, http_requests_total) quantile 用于计算当前样本数据值的分布情况 quantile(φ, express) ，其中 0 ≤ φ ≤ 1。 例如，当 φ 为 0.5 时，即表示找到当前样本数据中的中位数： quantile(0.5, http_requests_total) 返回结果如下： {} 656 二元运算符优先级 在 Prometheus 系统中，二元运算符优先级从高到低的顺序为： ^ *, /, % +, - ==, !=, , , >=, > and, unless or 具有相同优先级的运算符是满足结合律的（左结合）。例如，2 * 3 % 2 等价于 (2 * 3) % 2。运算符 ^ 例外，^ 满足的是右结合，例如，2 ^ 3 ^ 2 等价于 2 ^ (3 ^ 2)。 Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/functions.html":{"url":"3-prometheus/functions.html","title":"PromQL 内置函数","keywords":"","body":"PromQL 内置函数 Prometheus 提供了其它大量的内置函数，可以对时序数据进行丰富的处理。某些函数有默认的参数，例如：year(v=vector(time()) instant-vector)。其中参数 v 是一个瞬时向量，如果不提供该参数，将使用默认值 vector(time())。instant-vector 表示参数类型。 abs() abs(v instant-vector) 返回输入向量的所有样本的绝对值。 absent() absent(v instant-vector)，如果传递给它的向量参数具有样本数据，则返回空向量；如果传递的向量参数没有样本数据，则返回不带度量指标名称且带有标签的时间序列，且样本值为1。 当监控度量指标时，如果获取到的样本数据是空的， 使用 absent 方法对告警是非常有用的。例如： # 这里提供的向量有样本数据 absent(http_requests_total{method=\"get\"}) => no data absent(sum(http_requests_total{method=\"get\"})) => no data # 由于不存在度量指标 nonexistent，所以 返回不带度量指标名称且带有标签的时间序列，且样本值为1 absent(nonexistent{job=\"myjob\"}) => {job=\"myjob\"} 1 # 正则匹配的 instance 不作为返回 labels 中的一部分 absent(nonexistent{job=\"myjob\",instance=~\".*\"}) => {job=\"myjob\"} 1 # sum 函数返回的时间序列不带有标签，且没有样本数据 absent(sum(nonexistent{job=\"myjob\"})) => {} 1 ceil() ceil(v instant-vector) 将 v 中所有元素的样本值向上四舍五入到最接近的整数。例如： node_load5{instance=\"192.168.1.75:9100\"} # 结果为 2.79 ceil(node_load5{instance=\"192.168.1.75:9100\"}) # 结果为 3 changes() changes(v range-vector) 输入一个区间向量， 返回这个区间向量内每个样本数据值变化的次数（瞬时向量）。例如： # 如果样本数据值没有发生变化，则返回结果为 1 changes(node_load5{instance=\"192.168.1.75:9100\"}[1m]) # 结果为 1 clamp_max() clamp_max(v instant-vector, max scalar) 函数，输入一个瞬时向量和最大值，样本数据值若大于 max，则改为 max，否则不变。例如： node_load5{instance=\"192.168.1.75:9100\"} # 结果为 2.79 clamp_max(node_load5{instance=\"192.168.1.75:9100\"}, 2) # 结果为 2 clamp_min() clamp_min(v instant-vector, min scalar) 函数，输入一个瞬时向量和最小值，样本数据值若小于 min，则改为 min，否则不变。例如： node_load5{instance=\"192.168.1.75:9100\"} # 结果为 2.79 clamp_min(node_load5{instance=\"192.168.1.75:9100\"}, 3) # 结果为 3 day_of_month() day_of_month(v=vector(time()) instant-vector) 函数，返回被给定 UTC 时间所在月的第几天。返回值范围：1~31。 day_of_week() day_of_week(v=vector(time()) instant-vector) 函数，返回被给定 UTC 时间所在周的第几天。返回值范围：0~6，0 表示星期天。 days_in_month() days_in_month(v=vector(time()) instant-vector) 函数，返回当月一共有多少天。返回值范围：28~31。 delta() delta(v range-vector) 的参数是一个区间向量，返回一个瞬时向量。它计算一个区间向量 v 的第一个元素和最后一个元素之间的差值。由于这个值被外推到指定的整个时间范围，所以即使样本值都是整数，你仍然可能会得到一个非整数值。 例如，下面的例子返回过去两小时的 CPU 温度差： delta(cpu_temp_celsius{host=\"zeus\"}[2h]) 这个函数一般只用在 Gauge 类型的时间序列上。 deriv() deriv(v range-vector) 的参数是一个区间向量,返回一个瞬时向量。它使用简单的线性回归计算区间向量 v 中各个时间序列的导数。 这个函数一般只用在 Gauge 类型的时间序列上。 exp() exp(v instant-vector) 函数，输入一个瞬时向量，返回各个样本值的 e 的指数值，即 e 的 N 次方。当 N 的值足够大时会返回 +Inf。特殊情况为： Exp(+Inf) = +Inf Exp(NaN) = NaN floor() floor(v instant-vector) 函数与 ceil() 函数相反，将 v 中所有元素的样本值向下四舍五入到最接近的整数。 histogram_quantile() histogram_quantile(φ float, b instant-vector) 从 bucket 类型的向量 b 中计算 φ (0 ≤ φ ≤ 1) 分位数（百分位数的一般形式）的样本的最大值。（有关 φ 分位数的详细说明以及直方图指标类型的使用，请参阅直方图和摘要）。向量 b 中的样本是每个 bucket 的采样点数量。每个样本的 labels 中必须要有 le 这个 label 来表示每个 bucket 的上边界，没有 le 标签的样本会被忽略。直方图指标类型自动提供带有 _bucket 后缀和相应标签的时间序列。 可以使用 rate() 函数来指定分位数计算的时间窗口。 例如，一个直方图指标名称为 employee_age_bucket_bucket，要计算过去 10 分钟内 第 90 个百分位数，请使用以下表达式： histogram_quantile(0.9, rate(employee_age_bucket_bucket[10m])) 返回： {instance=\"10.0.86.71:8080\",job=\"prometheus\"} 35.714285714285715 这表示最近 10 分钟之内 90% 的样本的最大值为 35.714285714285715。 这个计算结果是每组标签组合成一个时间序列。我们可能不会对所有这些维度（如 job、instance 和 method）感兴趣，并希望将其中的一些维度进行聚合，则可以使用 sum() 函数。例如，以下表达式根据 job 标签来对第 90 个百分位数进行聚合： # histogram_quantile() 函数必须包含 le 标签 histogram_quantile(0.9, sum(rate(employee_age_bucket_bucket[10m])) by (job, le)) 如果要聚合所有的标签，则使用如下表达式： histogram_quantile(0.9,sum(rate(employee_age_bucket_bucket[10m])) by (le)) [info] 注意 histogram_quantile 这个函数是根据假定每个区间内的样本分布是线性分布来计算结果值的(也就是说它的结果未必准确)，最高的 bucket 必须是 le=\"+Inf\" (否则就返回 NaN)。 如果分位数位于最高的 bucket（+Inf） 中，则返回第二个最高的 bucket 的上边界。如果该 bucket 的上边界大于 0，则假设最低的 bucket 的的下边界为 0，这种情况下在该 bucket 内使用常规的线性插值。 如果分位数位于最低的 bucket 中，则返回最低 bucket 的上边界。 如果 b 含有少于 2 个 buckets，那么会返回 NaN，如果 φ -Inf，如果 φ > 1 会返回 +Inf。 holt_winters() holt_winters(v range-vector, sf scalar, tf scalar) 函数基于区间向量 v，生成时间序列数据平滑值。平滑因子 sf 越低, 对旧数据的重视程度越高。趋势因子 tf 越高，对数据的趋势的考虑就越多。其中，0。 holt_winters 仅适用于 Gauge 类型的时间序列。 hour() hour(v=vector(time()) instant-vector) 函数返回被给定 UTC 时间的当前第几个小时，时间范围：0~23。 idelta() idelta(v range-vector) 的参数是一个区间向量, 返回一个瞬时向量。它计算最新的 2 个样本值之间的差值。 这个函数一般只用在 Gauge 类型的时间序列上。 increase() increase(v range-vector) 函数获取区间向量中的第一个和最后一个样本并返回其增长量, 它会在单调性发生变化时(如由于采样目标重启引起的计数器复位)自动中断。由于这个值被外推到指定的整个时间范围，所以即使样本值都是整数，你仍然可能会得到一个非整数值。 例如，以下表达式返回区间向量中每个时间序列过去 5 分钟内 HTTP 请求数的增长数： increase(http_requests_total{job=\"apiserver\"}[5m]) increase 的返回值类型只能是计数器类型，主要作用是增加图表和数据的可读性。使用 rate 函数记录规则的使用率，以便持续跟踪数据样本值的变化。 irate() irate(v range-vector) 函数用于计算区间向量的增长率，但是其反应出的是瞬时增长率。irate 函数是通过区间向量中最后两个两本数据来计算区间向量的增长速率，它会在单调性发生变化时(如由于采样目标重启引起的计数器复位)自动中断。这种方式可以避免在时间窗口范围内的“长尾问题”，并且体现出更好的灵敏度，通过irate函数绘制的图标能够更好的反应样本数据的瞬时变化状态。 例如，以下表达式返回区间向量中每个时间序列过去 5 分钟内最后两个样本数据的 HTTP 请求数的增长率： irate(http_requests_total{job=\"api-server\"}[5m]) irate 只能用于绘制快速变化的计数器，在长期趋势分析或者告警中更推荐使用 rate 函数。因为使用 irate 函数时，速率的简短变化会重置 FOR 语句，形成的图形有很多波峰，难以阅读。 [info] 注意 当将 irate() 函数与聚合运算符（例如 sum()）或随时间聚合的函数（任何以 _over_time 结尾的函数）一起使用时，必须先执行 irate 函数，然后再进行聚合操作，否则当采样目标重新启动时 irate() 无法检测到计数器是否被重置。 label_join() label_join(v instant-vector, dst_label string, separator string, src_label_1 string, src_label_2 string, ...) 函数可以将时间序列 v 中多个标签 src_label 的值，通过 separator 作为连接符写入到一个新的标签 dst_label 中。可以有多个 src_label 标签。 例如，以下表达式返回的时间序列多了一个 foo 标签，标签值为 etcd,etcd-k8s： up{endpoint=\"api\",instance=\"192.168.123.248:2379\",job=\"etcd\",namespace=\"monitoring\",service=\"etcd-k8s\"} => up{endpoint=\"api\",instance=\"192.168.123.248:2379\",job=\"etcd\",namespace=\"monitoring\",service=\"etcd-k8s\"} 1 label_join(up{endpoint=\"api\",instance=\"192.168.123.248:2379\",job=\"etcd\",namespace=\"monitoring\",service=\"etcd-k8s\"}, \"foo\", \",\", \"job\", \"service\") => up{endpoint=\"api\",foo=\"etcd,etcd-k8s\",instance=\"192.168.123.248:2379\",job=\"etcd\",namespace=\"monitoring\",service=\"etcd-k8s\"} 1 label_replace() 为了能够让客户端的图标更具有可读性，可以通过 label_replace 函数为时间序列添加额外的标签。label_replace 的具体参数如下： label_replace(v instant-vector, dst_label string, replacement string, src_label string, regex string) 该函数会依次对 v 中的每一条时间序列进行处理，通过 regex 匹配 src_label 的值，并将匹配部分 relacement 写入到 dst_label 标签中。如下所示： label_replace(up, \"host\", \"$1\", \"instance\", \"(.*):.*\") 函数处理后，时间序列将包含一个 host 标签，host 标签的值为 Exporter 实例的 IP 地址： up{host=\"localhost\",instance=\"localhost:8080\",job=\"cadvisor\"} 1 up{host=\"localhost\",instance=\"localhost:9090\",job=\"prometheus\"} 1 up{host=\"localhost\",instance=\"localhost:9100\",job=\"node\"} 1 ln() ln(v instant-vector) 计算瞬时向量 v 中所有样本数据的自然对数。特殊情况： ln(+Inf) = +Inf ln(0) = -Inf ln(x ln(NaN) = NaN log2() log2(v instant-vector) 函数计算瞬时向量 v 中所有样本数据的二进制对数。特殊情况同上。 log10() log10(v instant-vector) 计算瞬时向量 v 中所有样本数据的十进制对数。特殊情况同上。 minute() minute(v=vector(time()) instant-vector) 函数返回给定 UTC 时间当前小时的第多少分钟。结果范围：0~59。 month() month(v=vector(time()) instant-vector) 函数返回给定 UTC 时间当前属于第几个月，结果范围：0~12。 predict_linear() predict_linear(v range-vector, t scalar) 函数可以预测时间序列 v 在 t 秒后的值。它基于简单线性回归的方式，对时间窗口内的样本数据进行统计，从而可以对时间序列的变化趋势做出预测。该函数的返回结果不带有度量指标，只有标签列表。 例如，基于 2 小时的样本数据，来预测主机可用磁盘空间的是否在 4 个小时候被占满，可以使用如下表达式： predict_linear(node_filesystem_free{job=\"node\"}[2h], 4 * 3600) 通过下面的例子来观察返回值： predict_linear(http_requests_total{code=\"200\",instance=\"120.77.65.193:9090\",job=\"prometheus\",method=\"get\"}[5m], 5) 结果： {code=\"200\",handler=\"query_range\",instance=\"120.77.65.193:9090\",job=\"prometheus\",method=\"get\"} 1 {code=\"200\",handler=\"prometheus\",instance=\"120.77.65.193:9090\",job=\"prometheus\",method=\"get\"} 4283.449995397104 {code=\"200\",handler=\"static\",instance=\"120.77.65.193:9090\",job=\"prometheus\",method=\"get\"} 22.99999999999999 ... 这个函数一般只用在 Gauge 类型的时间序列上。 rate() rate(v range-vector) 函数可以直接计算区间向量 v 在时间窗口内平均增长速率，它会在单调性发生变化时(如由于采样目标重启引起的计数器复位)自动中断。该函数的返回结果不带有度量指标，只有标签列表。 例如，以下表达式返回区间向量中每个时间序列过去 5 分钟内 HTTP 请求数的每秒增长率： rate(http_requests_total[5m]) 结果： {code=\"200\",handler=\"label_values\",instance=\"120.77.65.193:9090\",job=\"prometheus\",method=\"get\"} 0 {code=\"200\",handler=\"query_range\",instance=\"120.77.65.193:9090\",job=\"prometheus\",method=\"get\"} 0 {code=\"200\",handler=\"prometheus\",instance=\"120.77.65.193:9090\",job=\"prometheus\",method=\"get\"} 0.2 ... rate() 函数返回值类型只能用计数器，在长期趋势分析或者告警中推荐使用这个函数。 [info] 注意 当将 rate() 函数与聚合运算符（例如 sum()）或随时间聚合的函数（任何以 _over_time 结尾的函数）一起使用时，必须先执行 rate 函数，然后再进行聚合操作，否则当采样目标重新启动时 rate() 无法检测到计数器是否被重置。 resets() resets(v range-vector) 的参数是一个区间向量。对于每个时间序列，它都返回一个计数器重置的次数。两个连续样本之间的值的减少被认为是一次计数器重置。 这个函数一般只用在计数器类型的时间序列上。 round() round(v instant-vector, to_nearest=1 scalar) 函数与 ceil 和 floor 函数类似，返回向量中所有样本值的最接近的整数。to_nearest 参数是可选的,默认为 1,表示样本返回的是最接近 1 的整数倍的值。你也可以将该参数指定为任意值（也可以是小数），表示样本返回的是最接近它的整数倍的值。 scalar() scalar(v instant-vector) 函数的参数是一个单元素的瞬时向量,它返回其唯一的时间序列的值作为一个标量。如果度量指标的样本数量大于 1 或者等于 0, 则返回 NaN。 sort() sort(v instant-vector) 函数对向量按元素的值进行升序排序，返回结果：key: value = 度量指标：样本值[升序排列]。 sort_desc() sort(v instant-vector) 函数对向量按元素的值进行降序排序，返回结果：key: value = 度量指标：样本值[降序排列]。 sqrt() sqrt(v instant-vector) 函数计算向量 v 中所有元素的平方根。 time() time() 函数返回从 1970-01-01 到现在的秒数。注意：它不是直接返回当前时间，而是时间戳 timestamp() timestamp(v instant-vector) 函数返回向量 v 中的每个样本的时间戳（从 1970-01-01 到现在的秒数）。 该函数从 Prometheus 2.0 版本开始引入。 vector() vector(s scalar) 函数将标量 s 作为没有标签的向量返回，即返回结果为：key: value= {}, s。 year() year(v=vector(time()) instant-vector) 函数返回被给定 UTC 时间的当前年份。 _over_time() 下面的函数列表允许传入一个区间向量，它们会聚合每个时间序列的范围，并返回一个瞬时向量： avg_over_time(range-vector) : 区间向量内每个度量指标的平均值。 min_over_time(range-vector) : 区间向量内每个度量指标的最小值。 max_over_time(range-vector) : 区间向量内每个度量指标的最大值。 sum_over_time(range-vector) : 区间向量内每个度量指标的求和。 count_over_time(range-vector) : 区间向量内每个度量指标的样本数据个数。 quantile_over_time(scalar, range-vector) : 区间向量内每个度量指标的样本数据值分位数，φ-quantile (0 ≤ φ ≤ 1)。 stddev_over_time(range-vector) : 区间向量内每个度量指标的总体标准差。 stdvar_over_time(range-vector) : 区间向量内每个度量指标的总体标准方差。 [info] 注意 即使区间向量内的值分布不均匀，它们在聚合时的权重也是相同的。 Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/examples.html":{"url":"3-prometheus/examples.html","title":"简单示例","keywords":"","body":"简单示例 简单的时间序列选择 返回度量指标 http_requests_total 的所有时间序列样本数据： http_requests_total 返回度量指标名称为 http_requests_total，标签分别是 job=\"apiserver\", handler=\"/api/comments\" 的所有时间序列样本数据： http_requests_total{job=\"apiserver\", handler=\"/api/comments\"} 返回度量指标名称为 http_requests_total，标签分别是 job=\"apiserver\", handler=\"/api/comments\"，且是 5 分钟内的所有时间序列样本数据： http_requests_total{job=\"apiserver\", handler=\"/api/comments\"}[5m] [info] 注意 一个区间向量表达式不能直接展示在 Graph 图表中，但是可以展示在 Console 视图中。 使用正则表达式，你可以通过特定模式匹配标签为 job 的特定任务名，获取这些任务的时间序列。在下面这个例子中, 所有任务名称以 server 结尾。 http_requests_total{job=~\".*server\"} Prometheus中的所有正则表达式都使用 RE2 语法 返回度量指标名称是 http_requests_total， 且 http 返回码不以 4 开头的所有时间序列数据： http_requests_total{status!~\"4..\"} 使用函数，操作符等 返回度量指标 http_requests_total 过去 5 分钟内的 http 请求数的平均增长速率： rate(http_requests_total[5m]) 返回度量指标 http_requests_total 过去 5 分钟内的 http 请求数的平均增长速率总和，维度是 job： sum(rate(http_requests_total[5m])) by (job) 结果： {job=\"apiserver\"} 0.16666666666666666 {job=\"kubelet\"} 0.49999876544124355 如果两个指标具有相同维度的标签，我们可以使用二元操作符计算样本数据，返回值：key: value=标签列表：计算样本值。例如，以下表达式返回每一个实例的空闲内存，单位是 MiB。 (instance_memory_limit_bytes - instance_memory_usage_bytes) / 1024 / 1024 如果想知道每个应用的剩余内存，可以使用如下表达式： sum( instance_memory_limit_bytes - instance_memory_usage_bytes ) by (app, proc) / 1024 / 1024 如果相同的集群调度群显示如下的每个实例的 CPU 使用率： instance_cpu_time_ns{app=\"lion\", proc=\"web\", rev=\"34d0f99\", env=\"prod\", job=\"cluster-manager\"} instance_cpu_time_ns{app=\"elephant\", proc=\"worker\", rev=\"34d0f99\", env=\"prod\", job=\"cluster-manager\"} instance_cpu_time_ns{app=\"turtle\", proc=\"api\", rev=\"4d3a513\", env=\"prod\", job=\"cluster-manager\"} instance_cpu_time_ns{app=\"fox\", proc=\"widget\", rev=\"4d3a513\", env=\"prod\", job=\"cluster-manager\"} ... 我们可以按照应用和进程类型来获取 CPU 利用率最高的 3 个样本数据： topk(3, sum(rate(instance_cpu_time_ns[5m])) by (app, proc)) 假设一个服务实例只有一个时间序列数据，那么我们可以通过下面表达式统计出每个应用的实例数量： count(instance_cpu_time_ns) by (app) Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/api.html":{"url":"3-prometheus/api.html","title":"在 HTTP API 中使用 PromQL","keywords":"","body":"在 HTTP API 中使用 PromQL Prometheus 当前稳定的 HTTP API 可以通过 /api/v1 访问。 API 响应格式 Prometheus API 使用了 JSON 格式的响应内容。 当 API 调用成功后将会返回 2xx 的 HTTP 状态码。 反之，当 API 调用失败时可能返回以下几种不同的 HTTP 状态码： 404 Bad Request ：当参数错误或者缺失时。 422 Unprocessable Entity : 当表达式无法执行时。 503 Service Unavailable : 当请求超时或者被中断时。 所有的 API 请求返回的格式均使用以下的 JSON 格式： { \"status\": \"success\" | \"error\", \"data\": , // Only set if status is \"error\". The data field may still hold // additional data. \"errorType\": \"\", \"error\": \"\" } 输入时间戳可以由 RFC3339 格式或者 Unix 时间戳提供，后面可选的小数位可以精确到亚秒级别。输出时间戳以 Unix 时间戳的方式呈现。 查询参数名称可以用中括号 [] 重复次数。 占位符提供像 http_requests_total 或者 http_requests_total{method=~\"(GET|POST)\"} 的 Prometheus 时间序列选择器，并需要在 URL 中编码传输。 占位符指的是 [0-9]+[smhdwy] 形式的 Prometheus 持续时间字符串。例如：5m 表示 5 分钟的持续时间。 提供布尔值（字符串 true 和 false）。 表达式查询 通过 HTTP API 我们可以分别通过 /api/v1/query 和 /api/v1/query_range 查询 PromQL 表达式当前或者一定时间范围内的计算结果。 瞬时数据查询 通过使用 QUERY API 我们可以查询 PromQL 在特定时间点下的计算结果。 GET /api/v1/query URL 请求参数： query= : PromQL 表达式。 time= : 用于指定用于计算 PromQL 的时间戳。可选参数，默认情况下使用当前系统时间。 timeout= : 超时设置。可选参数，默认情况下使用全局设置的参数 -query.timeout。 如果 time 参数缺省，则使用当前服务器时间。 当 API 调用成功后，Prometheus 会返回 JSON 格式的响应内容，格式如上小节所示。并且在 data 部分返回查询结果。data 部分格式如下： { \"resultType\": \"matrix\" | \"vector\" | \"scalar\" | \"string\", \"result\": } 指的是查询结果数据，具体的格式取决于 resultType，不同的结果类型，会有不同的结果数据格式。参考 响应数据格式。 例如使用以下表达式查询表达式 up 在时间点 2015-07-01T20:10:51.781Z 的计算结果： $ curl 'http://localhost:9090/api/v1/query?query=up&time=2015-07-01T20:10:51.781Z' { \"status\" : \"success\", \"data\" : { \"resultType\" : \"vector\", \"result\" : [ { \"metric\" : { \"__name__\" : \"up\", \"job\" : \"prometheus\", \"instance\" : \"localhost:9090\" }, \"value\": [ 1435781451.781, \"1\" ] }, { \"metric\" : { \"__name__\" : \"up\", \"job\" : \"node\", \"instance\" : \"localhost:9100\" }, \"value\" : [ 1435781451.781, \"0\" ] } ] } } 区间数据查询 使用 QUERY_RANGE API 我们则可以直接查询 PromQL 表达式在一段时间返回内的计算结果。 GET /api/v1/query_range URL 请求参数： query= : PromQL 表达式。 start= : 起始时间戳。 end= : 结束时间戳。 step= : 查询时间步长，时间区间内每 step 秒执行一次。 timeout= : 超时设置。可选参数，默认情况下使用全局设置的参数 -query.timeout。 当使用 QUERY_RANGE API 查询 PromQL 表达式时，返回结果一定是一个区间向量： { \"resultType\": \"matrix\", \"result\": } [info] 注意 在 QUERY_RANGE API 中 PromQL 只能使用瞬时向量选择器类型的表达式。 对于 占位符的格式，详见 区间向量查询结果格式。 例如使用以下表达式查询表达式 up 在 30 秒范围内以 15 秒为间隔计算 PromQL 表达式的结果。 $ curl 'http://localhost:9090/api/v1/query_range?query=up&start=2015-07-01T20:10:30.781Z&end=2015-07-01T20:11:00.781Z&step=15s' { \"status\" : \"success\", \"data\" : { \"resultType\" : \"matrix\", \"result\" : [ { \"metric\" : { \"__name__\" : \"up\", \"job\" : \"prometheus\", \"instance\" : \"localhost:9090\" }, \"values\" : [ [ 1435781430.781, \"1\" ], [ 1435781445.781, \"1\" ], [ 1435781460.781, \"1\" ] ] }, { \"metric\" : { \"__name__\" : \"up\", \"job\" : \"node\", \"instance\" : \"localhost:9091\" }, \"values\" : [ [ 1435781430.781, \"0\" ], [ 1435781445.781, \"0\" ], [ 1435781460.781, \"1\" ] ] } ] } } 查询元数据 通过标签选择器查找时间序列 以下表达式返回与特定标签集匹配的时间序列列表： GET /api/v1/series URL 请求参数： match[]= : 表示标签选择器是 series_selector。必须至少提供一个 match[] 参数。 start= : 起始时间戳。 end= : 结束时间戳。 返回结果的 data 部分，是由 key-value 键值对的对象列表组成的。 例如使用以下表达式查询表达式 up 或 process_start_time_seconds{job=\"prometheus\"} 的计算结果： $ curl -g 'http://localhost:9090/api/v1/series?match[]=up&match[]=process_start_time_seconds{job=\"prometheus\"}' { \"status\" : \"success\", \"data\" : [ { \"__name__\" : \"up\", \"job\" : \"prometheus\", \"instance\" : \"localhost:9090\" }, { \"__name__\" : \"up\", \"job\" : \"node\", \"instance\" : \"localhost:9091\" }, { \"__name__\" : \"process_start_time_seconds\", \"job\" : \"prometheus\", \"instance\" : \"localhost:9090\" } ] } 查询标签值 下面这个例子返回了带有指定标签的的时间序列列表： GET /api/v1/label//values 返回结果的 data 部分是一个标签值列表。例如，以下表达式返回结果的 data 部分是标签名称为 job 的所有标签值： $ curl http://localhost:9090/api/v1/label/job/values { \"status\" : \"success\", \"data\" : [ \"node\", \"prometheus\" ] } 响应数据格式 表达式查询结果可能会在 data 部分的 result 字段中返回以下的响应值。其中 占位符是数值样本值。由于 json 不支持特殊浮点值，例如：NaN, Inf, 和 -Inf，所以样本值将会作为字符串（而不是原始数值）来进行传输。 区间向量 当返回数据类型 resultType 为 matrix 时，result 响应格式如下： [ { \"metric\": { \"\": \"\", ... }, \"values\": [ [ , \"\" ], ... ] }, ... ] 其中 metrics 表示当前时间序列的特征维度，values 包含当前事件序列的一组样本。 瞬时向量 当返回数据类型 resultType 为 vector 时，result 响应格式如下： [ { \"metric\": { \"\": \"\", ... }, \"value\": [ , \"\" ] }, ... ] 其中 metrics 表示当前时间序列的特征维度，values 包含当前事件序列的一组样本。 标量 当返回数据类型 resultType 为 scalar 时，result 响应格式如下： [ , \"\" ] 由于标量不存在时间序列一说，因此 result 表示为当前系统时间一个标量的值。 字符串 当返回数据类型 resultType 为 string 时，result 响应格式如下： [ , \"\" ] 字符串类型的响应内容格式和标量相同。 Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/storage.html":{"url":"3-prometheus/storage.html","title":"第5节：存储","keywords":"","body":"存储 Prometheus 2.x 默认将时间序列数据库保存在本地磁盘中，同时也可以将数据保存到任意第三方的存储服务中。 本地存储 Prometheus 采用自定义的存储格式将样本数据保存在本地磁盘当中。 存储格式 Prometheus 按照两个小时为一个时间窗口，将两小时内产生的数据存储在一个块（Block）中。每个块都是一个单独的目录，里面含该时间窗口内的所有样本数据（chunks），元数据文件（meta.json）以及索引文件（index）。其中索引文件会将指标名称和标签索引到样板数据的时间序列中。此期间如果通过 API 删除时间序列，删除记录会保存在单独的逻辑文件 tombstone 当中。 当前样本数据所在的块会被直接保存在内存中，不会持久化到磁盘中。为了确保 Prometheus 发生崩溃或重启时能够恢复数据，Prometheus 启动时会通过预写日志（write-ahead-log(WAL)）重新记录，从而恢复数据。预写日志文件保存在 wal 目录中，每个文件大小为 128MB。wal 文件包括还没有被压缩的原始数据，所以比常规的块文件大得多。一般情况下，Prometheus 会保留三个 wal 文件，但如果有些高负载服务器需要保存两个小时以上的原始数据，wal 文件的数量就会大于 3 个。 Prometheus保存块数据的目录结构如下所示： ./data |- 01BKGV7JBM69T2G1BGBGM6KB12 # 块 |- meta.json # 元数据 |- wal # 写入日志 |- 000002 |- 000001 |- 01BKGTZQ1SYQJTR4PB43C8PD98 # 块 |- meta.json #元数据 |- index # 索引文件 |- chunks # 样本数据 |- 000001 |- tombstones # 逻辑数据 |- 01BKGTZQ1HHWHV8FBJXW1Y3W0K |- meta.json |- wal |-000001 最初两个小时的块最终会在后台被压缩成更长的块。 [info] 注意 本地存储不可复制，无法构建集群，如果本地磁盘或节点出现故障，存储将无法扩展和迁移。因此我们只能把本地存储视为近期数据的短暂滑动窗口。如果你对数据持久化的要求不是很严格，可以使用本地磁盘存储多达数年的数据。 关于存储格式的详细信息，请参考 TSDB 格式 本地存储配置 Prometheus 提供了几个参数来修改本地存储的配置，最主要的有： 启动参数 默认值 含义 --storage.tsdb.path /data 数据存储路径 --storage.tsdb.retention.time 15d 样本数据在存储中保存的时间。超过该时间限制的数据就会被删除。 --storage.tsdb.retention.size 0 每个块的最大字节数（不包括 wal 文件）。如果超过限制，最早的样本数据会被优先删除。支持的单位有 KB, MB, GB, PB，例如：“512MB”。该参数只是试验性的，可能会在未来的版本中被移除。 --storage.tsdb.retention 该参数从 2.7 版本开始已经被弃用，使用 --storage.tsdb.retention.time 参数替代 在一般情况下，Prometheus 中存储的每一个样本大概占用1-2字节大小。如果需要对 Prometheus Server 的本地磁盘空间做容量规划时，可以通过以下公式计算： needed_disk_space = retention_time_seconds * ingested_samples_per_second * bytes_per_sample 从上面公式中可以看出在保留时间（retention_time_seconds）和样本大小（bytes_per_sample）不变的情况下，如果想减少本地磁盘的容量需求，只能通过减少每秒获取样本数（ingested_samples_per_second）的方式。因此有两种手段，一是减少时间序列的数量，二是增加采集样本的时间间隔。考虑到 Prometheus 会对时间序列进行压缩效率，减少时间序列的数量效果更明显。 如果你的本地存储出现故障，最好的办法是停止运行 Prometheus 并删除整个存储目录。因为 Prometheus 的本地存储不支持非 POSIX 兼容的文件系统，一旦发生损坏，将无法恢复。NFS 只有部分兼容 POSIX，大部分实现都不兼容 POSIX。 除了删除整个目录之外，你也可以尝试删除个别块目录来解决问题。删除每个块目录将会丢失大约两个小时时间窗口的样本数据。所以，Prometheus 的本地存储并不能实现长期的持久化存储。 如果同时指定了样本数据在存储中保存的时间和大小，则哪一个参数的限制先触发，就执行哪个参数的策略。 远程存储 Prometheus 的本地存储无法持久化数据，无法灵活扩展。为了保持Prometheus的简单性，Prometheus并没有尝试在自身中解决以上问题，而是通过定义两个标准接口（remote_write/remote_read），让用户可以基于这两个接口对接将数据保存到任意第三方的存储服务中，这种方式在 Promthues 中称为 Remote Storage。 Prometheus 可以通过两种方式来集成远程存储。 Remote Write 用户可以在 Prometheus 配置文件中指定 Remote Write（远程写）的 URL 地址，一旦设置了该配置项，Prometheus 将采集到的样本数据通过 HTTP 的形式发送给适配器（Adaptor）。而用户则可以在适配器中对接外部任意的服务。外部服务可以是真正的存储系统，公有云的存储服务，也可以是消息队列等任意形式。 Remote Read 如下图所示，Promthues 的 Remote Read（远程读）也通过了一个适配器实现。在远程读的流程当中，当用户发起查询请求后，Promthues 将向 remote_read 中配置的 URL 发起查询请求（matchers,ranges），Adaptor 根据请求条件从第三方存储服务中获取响应的数据。同时将数据转换为 Promthues 的原始样本数据返回给 Prometheus Server。 当获取到样本数据后，Promthues 在本地使用 PromQL 对样本数据进行二次处理。 [info] 注意 启用远程读设置后，Prometheus 仅从远程存储读取一组时序样本数据（根据标签选择器和时间范围），对于规则文件的处理，以及 Metadata API 的处理都只基于 Prometheus 本地存储完成。这也就意味着远程读在扩展性上有一定的限制，因为所有的样本数据都要首先加载到 Prometheus Server，然后再进行处理。所以 Prometheus 暂时不支持完全分布式处理。 远程读和远程写协议都使用了基于 HTTP 的 snappy 压缩协议的缓冲区编码，目前还不稳定，在以后的版本中可能会被替换成基于 HTTP/2 的 gRPC 协议，前提是 Prometheus 和远程存储之间的所有通信都支持 HTTP/2。 配置文件 想知道如何在 Prometheus 中添加远程存储的配置，请参考前面的章节：配置远程写 和 配置远程读。 关于请求与响应消息的详细信息，可以查看远程存储相关协议的 proto 文件： syntax = \"proto3\"; package prometheus; option go_package = \"prompb\"; import \"types.proto\"; import \"gogoproto/gogo.proto\"; message WriteRequest { repeated prometheus.TimeSeries timeseries = 1 [(gogoproto.nullable) = false]; } message ReadRequest { repeated Query queries = 1; } message ReadResponse { // In same order as the request's queries. repeated QueryResult results = 1; } message Query { int64 start_timestamp_ms = 1; int64 end_timestamp_ms = 2; repeated prometheus.LabelMatcher matchers = 3; prometheus.ReadHints hints = 4; } message QueryResult { // Samples within a time series must be ordered by time. repeated prometheus.TimeSeries timeseries = 1; } 支持的远程存储 目前 Prometheus 社区也提供了部分对于第三方数据库的 Remote Storage 支持： 存储服务 支持模式 AppOptics write Chronix write Cortex read/write CrateDB read/write Elasticsearch write Gnocchi write Graphite write InfluxDB read/write IRONdb read/write Kafka write M3DB read/write OpenTSDB write PostgreSQL/TimescaleDB read/write SignalFx write Splunk write TiKV read/write VictoriaMetrics write Wavefront write 更多信息请查看集成文档。 Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "},"3-prometheus/federation.html":{"url":"3-prometheus/federation.html","title":"第6节：联邦集群","keywords":"","body":"联邦 联邦使得一个 Prometheus 服务器可以从另一个 Prometheus 服务器提取选定的时序。 使用场景 Prometheus 联邦有不同的使用场景。通常，联邦被用来实现可扩展的 Prometheus 监控设置，或者将相关的指标从一个服务的 Prometheus 拉取到另一个 Prometheus 中。 分层联邦 分层联邦允许 Prometheus 能够扩展到十几个数据中心和上百万的节点。在此场景下，联邦拓扑类似一个树形拓扑结构，上层的 Prometheus 服务器从大量的下层 Prometheus 服务器中收集和汇聚的时序数据。 例如，一个联邦设置可能由多个数据中心中的 Prometheus 服务器和一套全局 Prometheus 服务器组成。每个数据中心中部署的 Prometheus 服务器负责收集本区域内细粒度的数据（实例级别），全局 Prometheus 服务器从这些下层 Prometheus 服务器中收集和汇聚数据（任务级别），并存储聚合后的数据。这样就提供了一个聚合的全局视角和详细的本地视角。 跨服务联邦 在跨服务联邦中，一个服务的 Prometheus 服务器被配置来提取来自其他服务的 Prometheus 服务器的指定的数据，以便在一个 Prometheus 服务器中对两个数据集启用告警和查询。 例如，一个运行多种服务的集群调度器可以暴露在集群上运行的服务实例的资源使用信息（例如内存和 CPU 使用率）。另一方面，运行在集群上的服务只需要暴露指定应用程序级别的服务指标。通常，这两种指标集分别被不同的 Prometheus 服务器抓取。利用联邦，监控服务级别指标的 Prometheus 服务器也可以从集群中 Prometheus 服务器拉取其特定服务的集群资源使用率指标，以便可以在该 Prometheus 服务器中使用这两组指标集 配置联邦 在 Prometheus 服务器中，/federate 节点允许获取服务中被选中的时间序列集合的值。至少一个 match[] URL 参数必须被指定为要暴露的序列。每个 match[] 变量需要被指定为一个不变的维度选择器像 up 或者 {job=\"api-server\"}。如果有多个 match[] 参数，则所有符合的时序数据的集合都会被选择。 从一个 Prometheus 服务器联邦指标到另一个 Prometheus 服务器，配置你的目标 Prometheus 服务器从源服务器的 /federate 节点抓取指标数据，同时也使用 honor_lables 抓取选项（不重写源 Prometheus 服务暴露的标签）并且传递需要的 match[] 参数。例如，下面的 scrape_configs 联邦 source-prometheus-{1,2,3}:9090 三台 Prometheus 服务器，上层 Prometheus 抓取并汇总他们暴露的任何带 job=\"prometheus\" 标签的序列或名称以 job: 开头的指标。 scrape_configs: - job_name: 'federate' scrape_interval: 15s honor_labels: true metrics_path: '/federate' params: 'match[]': - '{job=\"prometheus\"}' - '{__name__=~\"job:.*\"}' static_configs: - targets: - 'source-prometheus-1:9090' - 'source-prometheus-2:9090' - 'source-prometheus-3:9090' Copyright © www.yangcs.net 2018 all right reserved，powered by Gitbook Updated at 2019-08-29 00:11:45 "}}